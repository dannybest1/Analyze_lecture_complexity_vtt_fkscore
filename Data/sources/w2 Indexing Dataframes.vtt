WEBVTT

1
00:00:05.210 --> 00:00:07.470
As we've seen both Series and

2
00:00:07.470 --> 00:00:09.690
DataFrames can have
indices applied to them.

3
00:00:09.690 --> 00:00:12.390
The index is essentially
a row-level label and

4
00:00:12.390 --> 00:00:15.225
in Pandas the rows
correspond to axis zero.

5
00:00:15.225 --> 00:00:18.180
Indices can either
be autogenerated,

6
00:00:18.180 --> 00:00:20.805
such as when we created
a new Series without an index,

7
00:00:20.805 --> 00:00:22.755
in which case we get
a numeric value,

8
00:00:22.755 --> 00:00:24.540
or they can be set explicitly,

9
00:00:24.540 --> 00:00:26.520
like when we use
the dictionary object

10
00:00:26.520 --> 00:00:27.770
to create the Series,

11
00:00:27.770 --> 00:00:29.030
or when we load data from

12
00:00:29.030 --> 00:00:32.020
the CSV file and set
appropriate parameters.

13
00:00:32.020 --> 00:00:33.800
Another option for setting

14
00:00:33.800 --> 00:00:36.935
an index is to use the
set_index function.

15
00:00:36.935 --> 00:00:39.200
This function takes
a list of columns

16
00:00:39.200 --> 00:00:41.615
and promotes those
columns to an index.

17
00:00:41.615 --> 00:00:44.015
In this lecture,
we'll explore more

18
00:00:44.015 --> 00:00:46.930
about how indexes work in Pandas.

19
00:00:46.930 --> 00:00:50.870
The set_index function is
a destructive process,

20
00:00:50.870 --> 00:00:52.910
and it doesn't keep
the current index.

21
00:00:52.910 --> 00:00:54.660
If you want to keep
the current index,

22
00:00:54.660 --> 00:00:56.840
you need to manually
create a new column and

23
00:00:56.840 --> 00:00:59.840
copy into it values from
the index attribute.

24
00:00:59.840 --> 00:01:02.775
So let's import Pandas in
our admissions dataset.

25
00:01:02.775 --> 00:01:05.100
So import Pandas as pd.

26
00:01:05.100 --> 00:01:06.540
We'll create a new DataFrame,

27
00:01:06.540 --> 00:01:13.035
df equals pd.read_csv
datasets/Admissions_Predict.csv,

28
00:01:13.035 --> 00:01:15.120
and we'll set the index
column to zero,

29
00:01:15.120 --> 00:01:17.425
and let's look at
the head of this.

30
00:01:17.425 --> 00:01:19.700
So let's say that
we don't want to

31
00:01:19.700 --> 00:01:21.890
index the DataFrame
by serial numbers,

32
00:01:21.890 --> 00:01:24.050
but instead by
chance of admission.

33
00:01:24.050 --> 00:01:25.730
But let's assume we want to keep

34
00:01:25.730 --> 00:01:27.440
the serial number for later.

35
00:01:27.440 --> 00:01:30.905
So let's preserve the
serial number in a new column.

36
00:01:30.905 --> 00:01:33.245
We can do this using
the indexing operator

37
00:01:33.245 --> 00:01:35.540
on the string that
has the column label,

38
00:01:35.540 --> 00:01:37.760
then we can use
the set index to set

39
00:01:37.760 --> 00:01:40.690
the index of the column
to the chance of admit.

40
00:01:40.690 --> 00:01:43.895
So we copy the indexed data
into its own column,

41
00:01:43.895 --> 00:01:47.345
so df sub 'Serial
Number" equals df.index.

42
00:01:47.345 --> 00:01:48.830
So we just make a copy of that

43
00:01:48.830 --> 00:01:51.530
into a column that we've
labeled serial number,

44
00:01:51.530 --> 00:01:54.320
then we set the index
to another column.

45
00:01:54.320 --> 00:02:01.855
So df equals df.set_index
'Chance of Admit' and df.head.

46
00:02:01.855 --> 00:02:04.610
You'll see that when
we create a new index

47
00:02:04.610 --> 00:02:07.190
from an existing column
the index has a name,

48
00:02:07.190 --> 00:02:09.740
which is the original name
of the column.

49
00:02:09.740 --> 00:02:12.470
We can get rid of
the index completely by

50
00:02:12.470 --> 00:02:15.035
calling the function reset_index.

51
00:02:15.035 --> 00:02:17.510
This promotes the index
into a column,

52
00:02:17.510 --> 00:02:19.925
and creates a default
numbered index.

53
00:02:19.925 --> 00:02:24.745
So df equals df.reset_index,
and then df.head,

54
00:02:24.745 --> 00:02:26.600
and we see that
Chance of Admit is

55
00:02:26.600 --> 00:02:28.580
now promoted back into a column,

56
00:02:28.580 --> 00:02:30.760
and we have a numeric index.

57
00:02:30.760 --> 00:02:34.625
One nice feature of Pandas
is multi-level indexing.

58
00:02:34.625 --> 00:02:35.810
This is similar to

59
00:02:35.810 --> 00:02:38.885
composite keys in
relational database systems.

60
00:02:38.885 --> 00:02:40.870
To create a multi-level index,

61
00:02:40.870 --> 00:02:43.670
we simply call set_index
and give it a list

62
00:02:43.670 --> 00:02:45.080
of columns that we're interested

63
00:02:45.080 --> 00:02:47.150
in promoting to an index.

64
00:02:47.150 --> 00:02:49.850
Pandas will search
through these in order,

65
00:02:49.850 --> 00:02:53.900
finding the distinct data
and form composite indexes 

66
00:02:53.900 --> 00:02:55.990
A good example of this is often

67
00:02:55.990 --> 00:02:58.060
found when dealing with
geographical data,

68
00:02:58.060 --> 00:03:01.090
which is sorted by
regions or demographics.

69
00:03:01.090 --> 00:03:02.740
Let's change data sets,

70
00:03:02.740 --> 00:03:05.770
and look at some census data
for a better example.

71
00:03:05.770 --> 00:03:09.010
This data is stored in
the file census.csv.

72
00:03:09.010 --> 00:03:11.530
It comes from the United
States Census Bureau.

73
00:03:11.530 --> 00:03:13.510
In particular, this
is a breakdown of

74
00:03:13.510 --> 00:03:17.410
the population level data
in the US county level.

75
00:03:17.410 --> 00:03:19.590
It's a great example of
how different kinds of

76
00:03:19.590 --> 00:03:21.040
data sets might be formatted

77
00:03:21.040 --> 00:03:22.435
when you're trying to clean them.

78
00:03:22.435 --> 00:03:24.970
So let's import and see
what the data looks like.

79
00:03:24.970 --> 00:03:28.090
So df equals pd.read_ csv,

80
00:03:28.090 --> 00:03:30.700
and from data sets census.csv,

81
00:03:30.700 --> 00:03:32.455
and we'll look at the head.

82
00:03:32.455 --> 00:03:35.830
In this data set, there
are two summarized levels;

83
00:03:35.830 --> 00:03:38.770
one that contains summary data
for the whole country,

84
00:03:38.770 --> 00:03:41.405
and one that contains
summary data for each state.

85
00:03:41.405 --> 00:03:43.840
I want to see a list of
all the unique values

86
00:03:43.840 --> 00:03:45.035
in a given column.

87
00:03:45.035 --> 00:03:47.800
In this DataFrame, we see
that the possible values for

88
00:03:47.800 --> 00:03:49.240
the sum level are using

89
00:03:49.240 --> 00:03:51.340
the unique function
of the DataFrame.

90
00:03:51.340 --> 00:03:54.700
This is similar to
the SQL distinct operator.

91
00:03:54.700 --> 00:03:56.740
So here, we can run

92
00:03:56.740 --> 00:03:59.185
unique on the sum level
of our current DataFrame.

93
00:03:59.185 --> 00:04:01.615
So df, and we'll just project our

94
00:04:01.615 --> 00:04:05.590
SUMLEV and .unique to see
the unique values there.

95
00:04:05.590 --> 00:04:06.940
So we see that there's actually

96
00:04:06.940 --> 00:04:09.925
only two different
values; 40 and 50.

97
00:04:09.925 --> 00:04:12.595
Let's exclude all of the rows

98
00:04:12.595 --> 00:04:14.395
that are summaries
at the state level,

99
00:04:14.395 --> 00:04:16.330
and just keep the county data.

100
00:04:16.330 --> 00:04:18.265
So I'll override our DataFrame,

101
00:04:18.265 --> 00:04:20.455
df equals df sub,

102
00:04:20.455 --> 00:04:22.480
and we'll want to do that where

103
00:04:22.480 --> 00:04:25.835
df sub 'SUMLEV' is equal to 50,

104
00:04:25.835 --> 00:04:28.360
and let's look at
the head of that.

105
00:04:28.360 --> 00:04:30.575
Also, while this data set is

106
00:04:30.575 --> 00:04:33.000
interesting for a number
of different reasons,

107
00:04:33.000 --> 00:04:35.180
let's reduce the data
that we're going to look

108
00:04:35.180 --> 00:04:37.580
at to just the total
population estimates,

109
00:04:37.580 --> 00:04:39.260
and the total number of births.

110
00:04:39.260 --> 00:04:41.270
We can do this by
creating a list of

111
00:04:41.270 --> 00:04:43.550
column names that we want
to keep then project

112
00:04:43.550 --> 00:04:45.950
those and assign
the resulting DataFrame

113
00:04:45.950 --> 00:04:47.800
to our df variable.

114
00:04:47.800 --> 00:04:49.350
So columns to keep,

115
00:04:49.350 --> 00:04:51.795
and we'll write STNAME,

116
00:04:51.795 --> 00:04:55.620
CTYNAME, BIRTHS for 2010, 2011,

117
00:04:55.620 --> 00:05:01.815
-12, 13, 2014-15, and
then our POPESTIMATES for 10,

118
00:05:01.815 --> 00:05:05.835
11, 12, 13, 14, and 15.

119
00:05:05.835 --> 00:05:10.085
So our DataFrame is just
DataFrames sub columns_to_keep,

120
00:05:10.085 --> 00:05:12.410
and let's look at
the head of that.

121
00:05:12.410 --> 00:05:16.470
So smaller DataFrames,
still plenty big.

122
00:05:16.470 --> 00:05:18.850
The US Census data breaks down

123
00:05:18.850 --> 00:05:21.895
population estimates by
both state and county.

124
00:05:21.895 --> 00:05:24.430
We can load the data
and set the index to be

125
00:05:24.430 --> 00:05:27.010
a combination of the state
and county values,

126
00:05:27.010 --> 00:05:29.725
and see how Pandas handles
it in a DataFrame.

127
00:05:29.725 --> 00:05:31.630
We do this by creating a list of

128
00:05:31.630 --> 00:05:35.020
the column identifiers that
we want to make up the index,

129
00:05:35.020 --> 00:05:37.525
and then calling
set_index with this list,

130
00:05:37.525 --> 00:05:39.835
and assigning the output
as appropriate.

131
00:05:39.835 --> 00:05:41.320
We can have a dual index,

132
00:05:41.320 --> 00:05:42.590
so first the state name,

133
00:05:42.590 --> 00:05:44.075
and second the county name.

134
00:05:44.075 --> 00:05:47.660
So DataFrame equals df.set_index,

135
00:05:47.660 --> 00:05:49.130
and then I'm going to
pass it a list,

136
00:05:49.130 --> 00:05:51.020
and I want to have
first the state name,

137
00:05:51.020 --> 00:05:52.720
and then the county name,

138
00:05:52.720 --> 00:05:54.710
and let's look at
the head of that.

139
00:05:54.710 --> 00:05:58.010
That's a nice
rendering as well of

140
00:05:58.010 --> 00:06:02.525
how the counties are kept
within the state there.

141
00:06:02.525 --> 00:06:05.060
The immediate question
which comes up is

142
00:06:05.060 --> 00:06:06.875
how we can query this DataFrame.

143
00:06:06.875 --> 00:06:09.140
We saw previously that
the loc attribute of

144
00:06:09.140 --> 00:06:11.780
the DataFrame can take
multiple arguments,

145
00:06:11.780 --> 00:06:14.495
and it could query
both the row and the columns.

146
00:06:14.495 --> 00:06:16.325
When you use a MultiIndex,

147
00:06:16.325 --> 00:06:17.975
you must provide the arguments in

148
00:06:17.975 --> 00:06:20.455
order by the level
you wish to query.

149
00:06:20.455 --> 00:06:21.980
Inside of the index,

150
00:06:21.980 --> 00:06:23.780
each column is called a level and

151
00:06:23.780 --> 00:06:26.285
the outermost column
is level zero.

152
00:06:26.285 --> 00:06:28.880
So if I wanted to see
the population results

153
00:06:28.880 --> 00:06:31.760
from Washtenaw County
in Michigan the State

154
00:06:31.760 --> 00:06:33.050
which is where I live,

155
00:06:33.050 --> 00:06:35.300
the first argument
would be Michigan

156
00:06:35.300 --> 00:06:37.610
and the second would
be Washtenaw County.

157
00:06:37.610 --> 00:06:43.050
So df.loc sub 'Michigan',
'Washtenaw County'.

158
00:06:43.120 --> 00:06:46.370
If you are interested in
comparing two counties,

159
00:06:46.370 --> 00:06:49.010
for example, Washtenaw
and Wayne County,

160
00:06:49.010 --> 00:06:51.650
we can pass a list
of tuples describing

161
00:06:51.650 --> 00:06:55.940
the indices that we wish to
query into the loc attribute.

162
00:06:55.940 --> 00:06:58.535
Since we have a MultiIndex
of two values,

163
00:06:58.535 --> 00:06:59.690
the state and the county,

164
00:06:59.690 --> 00:07:01.580
we need to provide two values as

165
00:07:01.580 --> 00:07:04.040
each element of
our filtering list.

166
00:07:04.040 --> 00:07:06.245
Each tuple should
have two elements,

167
00:07:06.245 --> 00:07:08.270
the first element
being the first index,

168
00:07:08.270 --> 00:07:11.135
and the second element
being the second index.

169
00:07:11.135 --> 00:07:13.370
In this case, we
want to have a list

170
00:07:13.370 --> 00:07:15.050
of two tuples, in each tuple,

171
00:07:15.050 --> 00:07:16.685
the first element is Michigan,

172
00:07:16.685 --> 00:07:18.080
and the second element is

173
00:07:18.080 --> 00:07:20.725
either Washtenaw County,
or Wayne County.

174
00:07:20.725 --> 00:07:25.760
So df.loc and remember
we use the set operator,

175
00:07:25.760 --> 00:07:27.940
or the indexing operator on loc,

176
00:07:27.940 --> 00:07:30.950
and then we actually create
a list inside there,

177
00:07:30.950 --> 00:07:34.205
and the first is the tuple
Michigan and Washtenaw County,

178
00:07:34.205 --> 00:07:38.670
and the second is the tuple
Michigan and Wayne County.

179
00:07:39.380 --> 00:07:43.250
So that's how hierarchical
indices work in a nutshell.

180
00:07:43.250 --> 00:07:46.070
They're a special part of
the Pandas library which I

181
00:07:46.070 --> 00:07:47.450
think can make management and

182
00:07:47.450 --> 00:07:49.580
reasoning about data easier.

183
00:07:49.580 --> 00:07:52.670
Of course, hierarchical labeling
isn't just for rows.

184
00:07:52.670 --> 00:07:55.490
For example, you can
transpose this matrix,

185
00:07:55.490 --> 00:07:58.025
and now have hierarchical
column labels.

186
00:07:58.025 --> 00:08:00.215
Projecting a single
column which has

187
00:08:00.215 --> 00:08:02.090
these labels works
exactly the way

188
00:08:02.090 --> 00:08:03.730
that you would expect it to.

189
00:08:03.730 --> 00:08:06.380
Now, in reality, I don't tend to

190
00:08:06.380 --> 00:08:08.900
use hierarchical
indices very much,

191
00:08:08.900 --> 00:08:10.100
instead just keep everything as

192
00:08:10.100 --> 00:08:11.570
columns and manipulate those.

193
00:08:11.570 --> 00:08:14.420
But it's a unique and
sophisticated aspect

194
00:08:14.420 --> 00:08:16.160
of Pandas that's useful to know,

195
00:08:16.160 --> 00:08:20.100
especially if viewing
your data in a tabular form.