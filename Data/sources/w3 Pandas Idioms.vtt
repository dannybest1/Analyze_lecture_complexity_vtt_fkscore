WEBVTT

1
00:00:05.690 --> 00:00:08.070
Python programmers will often

2
00:00:08.070 --> 00:00:09.540
suggests that there are many ways

3
00:00:09.540 --> 00:00:12.780
the language can be used to
solve a particular problem,

4
00:00:12.780 --> 00:00:15.420
but that some are more
appropriate than others.

5
00:00:15.420 --> 00:00:19.170
The best solutions are
celebrated as idiomatic Python,

6
00:00:19.170 --> 00:00:20.970
and there's lots of
great examples on

7
00:00:20.970 --> 00:00:23.715
StackOverflow or other websites.

8
00:00:23.715 --> 00:00:26.550
As a sort of sub-language within Python,

9
00:00:26.550 --> 00:00:28.770
Pandas has its own set of idioms.

10
00:00:28.770 --> 00:00:30.990
We've alluded to some of
these already such as

11
00:00:30.990 --> 00:00:33.050
using vectorization
wherever possible,

12
00:00:33.050 --> 00:00:36.145
and not using iterative loops
if you don't need to.

13
00:00:36.145 --> 00:00:39.540
Several developers and users
within the Pandas community,

14
00:00:39.540 --> 00:00:42.320
have used the term pandorable
for these idioms,

15
00:00:42.320 --> 00:00:43.925
and I think it's a great term.

16
00:00:43.925 --> 00:00:46.550
So I wanted to share with you
a couple of key features of

17
00:00:46.550 --> 00:00:50.100
how you can make your
code more pandorable.

18
00:00:50.140 --> 00:00:52.550
So let's start by bringing in

19
00:00:52.550 --> 00:00:54.155
our Data Processing Library,

20
00:00:54.155 --> 00:00:55.430
so we'll bring in pandas,

21
00:00:55.430 --> 00:00:56.885
And we'll bring in numpy.

22
00:00:56.885 --> 00:00:59.560
We're going to bring in
some timing functionality too,

23
00:00:59.560 --> 00:01:02.780
so I want to demonstrate
something about idiomatic code,

24
00:01:02.780 --> 00:01:05.500
so we'll bring it from
the time at module.

25
00:01:05.500 --> 00:01:09.290
Let's look at some of
our census data from the US.

26
00:01:09.290 --> 00:01:12.450
So this is in the
DataFrame or the dataset,

27
00:01:12.450 --> 00:01:15.380
sorry, datasets/census.csv.

28
00:01:15.380 --> 00:01:16.690
We'll look at the head of that to

29
00:01:16.690 --> 00:01:18.930
remind ourselves what
that looks like.

30
00:01:18.930 --> 00:01:21.260
So the first of the
pandas idioms that I

31
00:01:21.260 --> 00:01:23.465
want to talk about is
called method chaining.

32
00:01:23.465 --> 00:01:26.180
The general idea behind
method chaining is that

33
00:01:26.180 --> 00:01:27.830
every method on object

34
00:01:27.830 --> 00:01:30.440
returns a reference
to that object.

35
00:01:30.440 --> 00:01:32.540
The beauty of this
is that you can

36
00:01:32.540 --> 00:01:35.690
condense many different
operations on a DataFrame,

37
00:01:35.690 --> 00:01:37.580
for instance into one line or

38
00:01:37.580 --> 00:01:39.985
at least one statement of code.

39
00:01:39.985 --> 00:01:41.950
So here's a pandorable way to

40
00:01:41.950 --> 00:01:43.810
write code with method chaining.

41
00:01:43.810 --> 00:01:46.300
In this code, I'm going
to pull out the state and

42
00:01:46.300 --> 00:01:48.700
the city names as
a multiple index,

43
00:01:48.700 --> 00:01:50.350
and I'm going to do so only for

44
00:01:50.350 --> 00:01:52.280
data which has
a summary level of 50,

45
00:01:52.280 --> 00:01:55.130
which in this dataset
is county-level data.

46
00:01:55.130 --> 00:01:56.530
I'm going to rename the column

47
00:01:56.530 --> 00:01:58.915
too just to make it
a bit more readable.

48
00:01:58.915 --> 00:02:02.175
So I'm going to say df.where

49
00:02:02.175 --> 00:02:06.855
the df sub some level equals 50,

50
00:02:06.855 --> 00:02:09.730
then I'm going to drop the NA
that we have from that.

51
00:02:09.730 --> 00:02:11.050
So you see the where
just returned to

52
00:02:11.050 --> 00:02:13.480
DataFrame and I just
called .dropna() on that,

53
00:02:13.480 --> 00:02:15.390
and then I'm going
to set the index,

54
00:02:15.390 --> 00:02:17.440
and I'm going use
a multiple index here.

55
00:02:17.440 --> 00:02:20.725
I want the state name and
the city name to be the index,

56
00:02:20.725 --> 00:02:22.390
and then I'm going to rename

57
00:02:22.390 --> 00:02:25.785
some values and so
the columns I'll

58
00:02:25.785 --> 00:02:28.175
change estimate based 2010 to

59
00:02:28.175 --> 00:02:31.475
something a little bit more
readable, we'll execute that.

60
00:02:31.475 --> 00:02:33.310
So let's walk through this.

61
00:02:33.310 --> 00:02:35.330
First, we use the where function

62
00:02:35.330 --> 00:02:36.650
on the DataFrame and pass in

63
00:02:36.650 --> 00:02:39.020
a Boolean mask which
is only true for

64
00:02:39.020 --> 00:02:41.780
those rows where
the sum level is equal to 50.

65
00:02:41.780 --> 00:02:43.790
This indicates in
our source data,

66
00:02:43.790 --> 00:02:46.405
that the data is summarized
at the county level.

67
00:02:46.405 --> 00:02:49.070
With the result of the where
function evaluated,

68
00:02:49.070 --> 00:02:50.660
we dropped missing values.

69
00:02:50.660 --> 00:02:52.490
Remember that where doesn't

70
00:02:52.490 --> 00:02:54.680
drop missing values by default.

71
00:02:54.680 --> 00:02:57.770
Then we said an index
on the result of that.

72
00:02:57.770 --> 00:02:59.120
In this case, I've set it to

73
00:02:59.120 --> 00:03:01.210
the state name followed
by the county name.

74
00:03:01.210 --> 00:03:04.640
Finally, I rename a column
to make it more readable.

75
00:03:04.640 --> 00:03:06.830
Note that instead
of writing this all

76
00:03:06.830 --> 00:03:08.810
on one line as I could've done,

77
00:03:08.810 --> 00:03:10.100
I began the statement with

78
00:03:10.100 --> 00:03:12.200
the parentheses which
tells Python that I'm

79
00:03:12.200 --> 00:03:13.880
going to expand
that statement over

80
00:03:13.880 --> 00:03:16.520
multiple lines for readability.

81
00:03:16.520 --> 00:03:18.680
Here's a more traditional non

82
00:03:18.680 --> 00:03:20.495
pandorable way of writing this.

83
00:03:20.495 --> 00:03:21.680
There's nothing wrong with

84
00:03:21.680 --> 00:03:23.060
the code in a functional sense.

85
00:03:23.060 --> 00:03:24.590
You might even be
able to understand it

86
00:03:24.590 --> 00:03:26.510
better as a new person
to the language.

87
00:03:26.510 --> 00:03:28.010
It's just not considered as

88
00:03:28.010 --> 00:03:30.365
pandorable as the first example.

89
00:03:30.365 --> 00:03:33.500
So let's create the new
DataFrame from the original,

90
00:03:33.500 --> 00:03:38.630
so df equals df sub df
SUMLEV equals 50.

91
00:03:38.630 --> 00:03:41.630
So here I'm using
the overloaded indexing operator

92
00:03:41.630 --> 00:03:42.950
which drops nans.

93
00:03:42.950 --> 00:03:45.020
So I'm actually doing
a couple of things,

94
00:03:45.020 --> 00:03:48.905
I'm projecting and creating
that Boolean array,

95
00:03:48.905 --> 00:03:51.230
and then I'm using that to

96
00:03:51.230 --> 00:03:54.230
project just certain values
out of the DataFrame,

97
00:03:54.230 --> 00:03:57.580
not a number values are
being dropped automatically,

98
00:03:57.580 --> 00:04:01.280
because that's the shortcut
that's been put in place.

99
00:04:01.280 --> 00:04:03.140
Then I'm going to
update the DataFrame

100
00:04:03.140 --> 00:04:04.220
to have a new index,

101
00:04:04.220 --> 00:04:05.450
and we're going to use in-place

102
00:04:05.450 --> 00:04:07.010
equals true to do this in place.

103
00:04:07.010 --> 00:04:08.960
So df.set index,

104
00:04:08.960 --> 00:04:11.340
and then I'll pass in the
columns I'm interested in,

105
00:04:11.340 --> 00:04:13.520
and then the in-place
equals true tells

106
00:04:13.520 --> 00:04:16.160
the DataFrame to
just modify itself.

107
00:04:16.160 --> 00:04:17.690
Then I'm going to set
the column names,

108
00:04:17.690 --> 00:04:19.040
so I just rename the columns

109
00:04:19.040 --> 00:04:21.070
and this looks pretty
much the same,

110
00:04:21.070 --> 00:04:23.645
and we see we get
a similar result.

111
00:04:23.645 --> 00:04:25.190
So now the key with

112
00:04:25.190 --> 00:04:28.775
any good idiom is to understand
when it isn't helping.

113
00:04:28.775 --> 00:04:30.800
In this case, you
can actually time

114
00:04:30.800 --> 00:04:33.665
both methods to see
which one runs faster.

115
00:04:33.665 --> 00:04:36.770
So we could put the approach
into a function and pass

116
00:04:36.770 --> 00:04:39.620
the function into the time
function to count the time,

117
00:04:39.620 --> 00:04:42.770
the parameter, number
for time it allows us to

118
00:04:42.770 --> 00:04:44.300
choose how many times we want

119
00:04:44.300 --> 00:04:46.100
to actually run that function.

120
00:04:46.100 --> 00:04:48.680
So here I'm just going
to set it to 10.

121
00:04:48.680 --> 00:04:50.870
So let's write a wrapper
for our first function.

122
00:04:50.870 --> 00:04:53.285
So I'm going to define
first approach,

123
00:04:53.285 --> 00:04:55.345
we'll make global DataFrame,

124
00:04:55.345 --> 00:04:58.535
and we'll just paste
our SUM code right in here.

125
00:04:58.535 --> 00:05:01.520
So just to our
pandorable code in here,

126
00:05:01.520 --> 00:05:03.170
and we're just returning all of

127
00:05:03.170 --> 00:05:06.140
that as a result of
that first approach.

128
00:05:06.140 --> 00:05:09.170
I'm going to read
in a new dataset.

129
00:05:09.170 --> 00:05:10.850
So it's nice and fresh.

130
00:05:10.850 --> 00:05:12.290
So df, and remember in

131
00:05:12.290 --> 00:05:15.050
our function we've
made this global df,

132
00:05:15.050 --> 00:05:16.730
and now we're just
going to run it.

133
00:05:16.730 --> 00:05:20.240
So I'm going to call timeit.timeit
pass it the function,

134
00:05:20.240 --> 00:05:22.950
tell it how many times
I wanted to run.

135
00:05:24.320 --> 00:05:27.165
Now let's test the
second approach,

136
00:05:27.165 --> 00:05:28.700
and as you notice we're using

137
00:05:28.700 --> 00:05:31.655
the global variable df
and the function.

138
00:05:31.655 --> 00:05:33.980
However changing
a global variable inside

139
00:05:33.980 --> 00:05:35.270
of a function will modify

140
00:05:35.270 --> 00:05:36.560
the variable even in

141
00:05:36.560 --> 00:05:37.640
a global scope and we

142
00:05:37.640 --> 00:05:39.380
don't want that to
happen in this case.

143
00:05:39.380 --> 00:05:42.650
So for selecting
summary levels of 50 only,

144
00:05:42.650 --> 00:05:45.335
I have created a new DataFrame
for those records.

145
00:05:45.335 --> 00:05:49.550
So let's run this for 10
times and see how it is.

146
00:05:49.550 --> 00:05:51.950
So def second approach and I'll

147
00:05:51.950 --> 00:05:54.340
just paste the code from
the second approach.

148
00:05:54.340 --> 00:05:56.030
You can see that
it's basically the

149
00:05:56.030 --> 00:05:58.495
same as we spoke about,

150
00:05:58.495 --> 00:06:01.100
and then I'm going to
read in a new dataset.

151
00:06:01.100 --> 00:06:04.040
So we'll read this
from the census.csv,

152
00:06:04.040 --> 00:06:07.100
and now let's run it and
do our timing on it.

153
00:06:07.100 --> 00:06:09.470
So timeit.timeit, and we'll pass

154
00:06:09.470 --> 00:06:12.665
in second approach and we'll
run that 10 times as well.

155
00:06:12.665 --> 00:06:16.340
So as you can see the
second approach is much faster,

156
00:06:16.340 --> 00:06:18.680
and so in this
particular example it's

157
00:06:18.680 --> 00:06:22.830
actually a classic time
readability trade off.

158
00:06:22.880 --> 00:06:26.605
You'll see lots of examples
on StackOverflow in

159
00:06:26.605 --> 00:06:29.140
documentation of people using

160
00:06:29.140 --> 00:06:30.880
method chaining in their pandas.

161
00:06:30.880 --> 00:06:32.620
So I think it's really important

162
00:06:32.620 --> 00:06:33.760
for you to be able to read and

163
00:06:33.760 --> 00:06:35.410
understand the syntax and it's

164
00:06:35.410 --> 00:06:37.720
really worth your time
to investigate this.

165
00:06:37.720 --> 00:06:40.555
But keep in mind that
following what appears to be

166
00:06:40.555 --> 00:06:44.139
stylistic idioms might
have performance issues,

167
00:06:44.139 --> 00:06:47.050
and you need to consider
this as well really depends

168
00:06:47.050 --> 00:06:51.340
on the scope of the Data
cleaning you're doing.

169
00:06:51.340 --> 00:06:53.320
Here's another pandas idiom.

170
00:06:53.320 --> 00:06:55.840
Python has a wonderful function
called map which is

171
00:06:55.840 --> 00:06:59.015
a basis for functional
programming in the language.

172
00:06:59.015 --> 00:07:00.965
When you want to
use map and python,

173
00:07:00.965 --> 00:07:02.650
you pass it to
some function you want

174
00:07:02.650 --> 00:07:04.915
called and some
iterable like a list,

175
00:07:04.915 --> 00:07:06.985
then you want the function
to be applied to.

176
00:07:06.985 --> 00:07:08.780
The results of that function

177
00:07:08.780 --> 00:07:10.860
are then called against
each item in the list,

178
00:07:10.860 --> 00:07:12.770
and there's a
resulting list of all

179
00:07:12.770 --> 00:07:15.185
of the evaluations
of that function.

180
00:07:15.185 --> 00:07:17.480
So pandas has something similar,

181
00:07:17.480 --> 00:07:18.860
and it's called apply map,

182
00:07:18.860 --> 00:07:21.500
and then apply map you
provide some function

183
00:07:21.500 --> 00:07:24.559
which should operate on
each cell of the DataFrame,

184
00:07:24.559 --> 00:07:27.620
and the return set is
itself a DataFrame.

185
00:07:27.620 --> 00:07:29.420
Now, I think apply map is

186
00:07:29.420 --> 00:07:31.460
fine but I actually
rarely use it.

187
00:07:31.460 --> 00:07:34.835
Instead, I find myself
often wanting to map across

188
00:07:34.835 --> 00:07:38.675
all of the rows in the
DataFrame not just the cells,

189
00:07:38.675 --> 00:07:40.550
and so pandas actually
has a function that I

190
00:07:40.550 --> 00:07:42.785
use quite heavily
there called apply,

191
00:07:42.785 --> 00:07:45.095
and so let's take
a look at an example.

192
00:07:45.095 --> 00:07:48.155
So let's look at
our census DataFrame.

193
00:07:48.155 --> 00:07:50.275
In this data frame,
we have five columns

194
00:07:50.275 --> 00:07:51.700
for population estimates,

195
00:07:51.700 --> 00:07:53.230
with each column corresponding

196
00:07:53.230 --> 00:07:54.990
with one year of estimates.

197
00:07:54.990 --> 00:07:57.130
It's quite reasonable
to want to create

198
00:07:57.130 --> 00:07:59.845
some new columns for
minimum or maximum values,

199
00:07:59.845 --> 00:08:02.695
and the apply function is
an easy way to do this.

200
00:08:02.695 --> 00:08:04.750
So first we need to write

201
00:08:04.750 --> 00:08:07.195
a function which takes in
a particular row of data,

202
00:08:07.195 --> 00:08:09.320
finds a minimum
and maximum value,

203
00:08:09.320 --> 00:08:12.460
and returns a new row
of data from that.

204
00:08:12.460 --> 00:08:14.475
We'll call this function min-max.

205
00:08:14.475 --> 00:08:15.955
This is pretty straight forward.

206
00:08:15.955 --> 00:08:17.620
We can create
a small slice of a row

207
00:08:17.620 --> 00:08:19.675
by projecting
the population columns,

208
00:08:19.675 --> 00:08:20.920
then we can use NumPy,

209
00:08:20.920 --> 00:08:23.260
min and max functions and
create a new series with

210
00:08:23.260 --> 00:08:25.100
the label values representing

211
00:08:25.100 --> 00:08:27.070
the new value that
we want applied.

212
00:08:27.070 --> 00:08:31.490
So def min-max, and we'll
pass it row and then data,

213
00:08:31.490 --> 00:08:33.810
we're just going to project
the rows that we're

214
00:08:33.810 --> 00:08:36.195
actually interested in
from the data frame.

215
00:08:36.195 --> 00:08:37.480
So from this row,

216
00:08:37.480 --> 00:08:40.535
we're just going to bring in
our population estimates,

217
00:08:40.535 --> 00:08:43.295
and then we're just going
to return a new series.

218
00:08:43.295 --> 00:08:44.925
In this new series,

219
00:08:44.925 --> 00:08:47.700
we're we've got two values
a min and a max,

220
00:08:47.700 --> 00:08:49.260
and we're going to pass in

221
00:08:49.260 --> 00:08:52.805
NumPy min and
the NumPy max from Data.

222
00:08:52.805 --> 00:08:56.205
So then we just need to call
apply on the data frame.

223
00:08:56.205 --> 00:08:58.210
Apply takes the function and

224
00:08:58.210 --> 00:09:00.885
the axis on which to
operate as parameters.

225
00:09:00.885 --> 00:09:03.070
Now, we have to be a bit careful.

226
00:09:03.070 --> 00:09:05.355
We've talked about axes zero

227
00:09:05.355 --> 00:09:07.740
being the rows of
the data frame in the past,

228
00:09:07.740 --> 00:09:09.225
but this parameter is really

229
00:09:09.225 --> 00:09:11.480
a parameter of the index to use.

230
00:09:11.480 --> 00:09:13.485
So to apply across all rows,

231
00:09:13.485 --> 00:09:15.355
which is applying
across all columns,

232
00:09:15.355 --> 00:09:18.060
you can pass an
axis equal to one,

233
00:09:18.060 --> 00:09:20.775
or equal to the word
columns itself.

234
00:09:20.775 --> 00:09:25.095
So df.apply, we push in
our min-max function.

235
00:09:25.095 --> 00:09:27.150
Here I'll set the axis
equal to columns,

236
00:09:27.150 --> 00:09:29.170
and let's look at
the head of this.

237
00:09:29.170 --> 00:09:31.460
Of course, there's
no need to limit

238
00:09:31.460 --> 00:09:34.140
yourself to returning
a new series object.

239
00:09:34.140 --> 00:09:36.290
If you're doing this as
part of data cleaning,

240
00:09:36.290 --> 00:09:38.410
you're likely to find
yourself wanting to

241
00:09:38.410 --> 00:09:40.935
add new data to
the existing data frame.

242
00:09:40.935 --> 00:09:43.510
In that case, you can
just take the row values,

243
00:09:43.510 --> 00:09:47.310
and add in new columns indicating
the max and min scores.

244
00:09:47.310 --> 00:09:49.750
This is a regular part
of my workflow

245
00:09:49.750 --> 00:09:52.060
when bringing in data and
bring building summary,

246
00:09:52.060 --> 00:09:54.410
or descriptive
statistics, and is often

247
00:09:54.410 --> 00:09:57.590
used heavily with
the merging of data frames.

248
00:09:57.590 --> 00:09:59.595
Here's an example where we have

249
00:09:59.595 --> 00:10:01.930
a revised version of
the function min-max.

250
00:10:01.930 --> 00:10:03.700
Instead of returning
a separate series

251
00:10:03.700 --> 00:10:05.085
to display the min and max,

252
00:10:05.085 --> 00:10:06.740
we add two new columns to

253
00:10:06.740 --> 00:10:09.390
the original data frame
to store min.

254
00:10:09.390 --> 00:10:11.295
So I'll just def min-max.

255
00:10:11.295 --> 00:10:14.940
Again, I'm going to bring in
all the population row Data,

256
00:10:14.940 --> 00:10:17.710
and now I'm going to create
a new entry for max.

257
00:10:17.710 --> 00:10:21.090
So I just say row sub max
equals np.max of data,

258
00:10:21.090 --> 00:10:24.690
and then we can create
a new entry for the min as well.

259
00:10:24.690 --> 00:10:27.705
So row sub min
equals np.min(Data),

260
00:10:27.705 --> 00:10:29.770
and then we'll just return row.

261
00:10:29.770 --> 00:10:31.845
So now we actually have all of

262
00:10:31.845 --> 00:10:33.520
our pop estimate data in

263
00:10:33.520 --> 00:10:36.370
the row as well as
our max and our min.

264
00:10:36.370 --> 00:10:38.700
So we just apply this.

265
00:10:38.700 --> 00:10:41.090
Again, we want to say df.apply

266
00:10:41.090 --> 00:10:43.390
passing the function we're
interested in applying,

267
00:10:43.390 --> 00:10:46.950
and then say that we want
this applied across columns.

268
00:10:46.950 --> 00:10:51.115
So apply is an extremely
important tool in your toolkit.

269
00:10:51.115 --> 00:10:53.115
The reason I
introduced apply here,

270
00:10:53.115 --> 00:10:56.140
is because you rarely
see it being used with

271
00:10:56.140 --> 00:10:59.500
actually such large function
definitions like we did,

272
00:10:59.500 --> 00:11:02.910
instead you typically see
it being used with Lambdas.

273
00:11:02.910 --> 00:11:05.275
To get the most out
of this discussion,

274
00:11:05.275 --> 00:11:07.295
and the discussions
that you'll see online,

275
00:11:07.295 --> 00:11:10.350
you're going to need to
know how to read Lambdas.

276
00:11:10.350 --> 00:11:12.670
So you can imagine how you might

277
00:11:12.670 --> 00:11:14.650
chain several apply calls with

278
00:11:14.650 --> 00:11:15.910
lambdas together to create

279
00:11:15.910 --> 00:11:19.335
a readable yet succinct
data manipulation script.

280
00:11:19.335 --> 00:11:21.700
One line example of how
you might calculate

281
00:11:21.700 --> 00:11:24.040
the max of the columns
using the apply function,

282
00:11:24.040 --> 00:11:25.555
is something we're
going to do here.

283
00:11:25.555 --> 00:11:27.270
So I'll bring in the rows,

284
00:11:27.270 --> 00:11:30.185
again these are
my population estimate rows,

285
00:11:30.185 --> 00:11:31.515
and now we'll just apply this

286
00:11:31.515 --> 00:11:33.460
across the data frame
with Lambdas.

287
00:11:33.460 --> 00:11:37.555
So df.apply, and then I
pass into apply Lambda x,

288
00:11:37.555 --> 00:11:40.420
and I just want np.max x sub

289
00:11:40.420 --> 00:11:43.390
rows and then here I'm
saying axis equals one.

290
00:11:43.390 --> 00:11:45.355
I could have said
axis equals column,

291
00:11:45.355 --> 00:11:47.050
one and column are synonymous

292
00:11:47.050 --> 00:11:50.800
and row and zero are Synonymous,

293
00:11:50.800 --> 00:11:53.215
and then we'll take
the head of that.

294
00:11:53.215 --> 00:11:56.320
So this is something
that you'll commonly

295
00:11:56.320 --> 00:11:59.200
see in StackOverflow examples,

296
00:11:59.200 --> 00:12:02.685
or messages, or even the
official documentation.

297
00:12:02.685 --> 00:12:04.695
If you don't remember Lambdas,

298
00:12:04.695 --> 00:12:07.690
just pause the video for
a moment and look up the syntax.

299
00:12:07.690 --> 00:12:11.070
A lambda is just an unnamed
function in Python.

300
00:12:11.070 --> 00:12:12.400
In this case, it takes in

301
00:12:12.400 --> 00:12:15.510
a single parameter x and
returns a single value.

302
00:12:15.510 --> 00:12:17.260
In this case the maximum over

303
00:12:17.260 --> 00:12:20.135
all the columns
associated with row x.

304
00:12:20.135 --> 00:12:23.205
The beauty of the applied
function is that it allows

305
00:12:23.205 --> 00:12:24.460
flexibility in doing

306
00:12:24.460 --> 00:12:26.865
whatever manipulation
that you desire,

307
00:12:26.865 --> 00:12:29.150
as the function you
pass into apply can

308
00:12:29.150 --> 00:12:31.740
be any customized function
that you want.

309
00:12:31.740 --> 00:12:33.345
So let's say we wanted to divide

310
00:12:33.345 --> 00:12:35.125
the states into four categories;

311
00:12:35.125 --> 00:12:37.965
Northeast, Midwest,
South, and West.

312
00:12:37.965 --> 00:12:40.390
We can write customized function

313
00:12:40.390 --> 00:12:42.580
that returns this region
based on the state,

314
00:12:42.580 --> 00:12:44.545
and the state
regions information,

315
00:12:44.545 --> 00:12:46.875
maybe we looked up on Wikipedia.

316
00:12:46.875 --> 00:12:50.380
So here I'll write
a function def get_state_region,

317
00:12:50.380 --> 00:12:51.700
and for the Northeast,

318
00:12:51.700 --> 00:12:53.680
I'll just have a nice big list

319
00:12:53.680 --> 00:12:56.070
of states in the north east,

320
00:12:56.070 --> 00:12:59.395
the Midwest and of course
the most important region,

321
00:12:59.395 --> 00:13:04.120
we'll put in a bunch of
states from the Midwest,

322
00:13:04.120 --> 00:13:05.770
and there's lots of
states here and they're

323
00:13:05.770 --> 00:13:09.355
all very important especially
that third one there.

324
00:13:09.355 --> 00:13:12.110
Then for south, we'll bring

325
00:13:12.110 --> 00:13:16.015
in all the states that we
want in the south region,

326
00:13:16.015 --> 00:13:17.805
and then the states that we

327
00:13:17.805 --> 00:13:20.160
want to bring in from
the west as well.

328
00:13:20.160 --> 00:13:22.260
Then we're just going
to write a little if else.

329
00:13:22.260 --> 00:13:24.970
So if x is in the northeast
return northeast,

330
00:13:24.970 --> 00:13:27.480
if x is in Midwest
return Midwest,

331
00:13:27.480 --> 00:13:28.905
do the same for South,

332
00:13:28.905 --> 00:13:31.375
and we'll do the same for west.

333
00:13:31.375 --> 00:13:34.270
You can imagine that
there's many ways that we

334
00:13:34.270 --> 00:13:36.695
could have written that function.

335
00:13:36.695 --> 00:13:38.905
So now we have
a customized function.

336
00:13:38.905 --> 00:13:41.455
Let's say we want to create
a new column called region,

337
00:13:41.455 --> 00:13:43.180
which shows the state region,

338
00:13:43.180 --> 00:13:45.105
we can use the
customized function

339
00:13:45.105 --> 00:13:47.020
and the apply function to do so.

340
00:13:47.020 --> 00:13:49.365
The customized function
is supposed to work on

341
00:13:49.365 --> 00:13:51.750
the state Name column, STNAME.

342
00:13:51.750 --> 00:13:54.670
So we'll set the apply function
to the state name column,

343
00:13:54.670 --> 00:13:57.955
and pass the customized
function into the Apply.

344
00:13:57.955 --> 00:13:59.200
So here's our example.

345
00:13:59.200 --> 00:14:01.065
We're going to create
a new column in

346
00:14:01.065 --> 00:14:03.160
our data frame
called state region,

347
00:14:03.160 --> 00:14:05.890
we're going to make this
equal to df sub state names,

348
00:14:05.890 --> 00:14:09.010
so we're just projecting
a single columns.

349
00:14:09.010 --> 00:14:10.285
So this isn't series,

350
00:14:10.285 --> 00:14:13.080
but it also has a .apply function.

351
00:14:13.080 --> 00:14:16.785
So we'll call .apply, and
we'll pass in a Lambda,

352
00:14:16.785 --> 00:14:18.520
and that Lambda is
just going to take

353
00:14:18.520 --> 00:14:20.285
whatever value it sees there,

354
00:14:20.285 --> 00:14:22.980
and call the Get
state region to it.

355
00:14:22.980 --> 00:14:26.025
So let's take a look
at those results.

356
00:14:26.025 --> 00:14:30.100
So even though it was a series
that we were working on,

357
00:14:30.100 --> 00:14:33.855
we assign that to
a data frame projections slice.

358
00:14:33.855 --> 00:14:36.315
So that means we've got
our full data frame still.

359
00:14:36.315 --> 00:14:38.440
So we'll take a look
at df sub state name,

360
00:14:38.440 --> 00:14:40.705
and state region and
the head of that.

361
00:14:40.705 --> 00:14:42.290
So we can see here that we have

362
00:14:42.290 --> 00:14:47.420
both the state name and the
state region throughout.

363
00:14:47.730 --> 00:14:50.980
So there are a couple
of pandas idioms,

364
00:14:50.980 --> 00:14:52.100
but I think there's many

365
00:14:52.100 --> 00:14:54.120
more that I haven't
talked about here,

366
00:14:54.120 --> 00:14:56.705
and there's an unofficial
assignment for you.

367
00:14:56.705 --> 00:14:58.510
Go look at some of the top ranked

368
00:14:58.510 --> 00:15:01.070
questions on pandas,
on stack, overflow,

369
00:15:01.070 --> 00:15:02.620
you're going to learn
a lot from that,

370
00:15:02.620 --> 00:15:05.350
and look at how some of
the more experienced authors

371
00:15:05.350 --> 00:15:07.005
answer those questions.

372
00:15:07.005 --> 00:15:09.145
Do you see any
interesting patterns?

373
00:15:09.145 --> 00:15:10.845
Feel free to share
them with others in

374
00:15:10.845 --> 00:15:12.680
the class and myself
so that we can

375
00:15:12.680 --> 00:15:17.340
learn more about what
idiomatic pandas looks like.